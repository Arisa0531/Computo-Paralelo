import pandas as pd
import itertools
import threading
import time
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score

# Cargar y preprocesar la base de datos
file_path = r'C:\Users\Ariadna\Downloads\winequality-white-clean.csv'
df = pd.read_csv(file_path)

# Separar características (X) y la etiqueta (y)
X = df.drop(columns=['quality'])
y = df['quality']

# (80% entrenamiento, 20% prueba)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

# Definir los hiperparámetros para Random Forest
param_grid_rf = {
    'n_estimators': [10, 50, 100],
    'criterion': ['gini', 'entropy'],
    'max_depth': [10, 20, None]
}

# Generar todas las combinaciones posibles de hiperparámetros
keys_rf, values_rf = zip(*param_grid_rf.items())
combinations_rf = [dict(zip(keys_rf, v)) for v in itertools.product(*values_rf)]

# Validación cruzada
def evaluate_set(hyperparameter_set, X_train, y_train, results, idx):
    best_accuracy = 0
    best_params = None

    # Creamos una copia de los datos en cada hilo para evitar problemas de escritura
    X_train_local = X_train.copy()
    y_train_local = y_train.copy()

    for params in hyperparameter_set:
        clf = RandomForestClassifier(**params)
        # Usar validación cruzada en el conjunto de entrenamiento
        scores = cross_val_score(clf, X_train_local, y_train_local, cv=5)  # 5-fold cross-validation
        accuracy = scores.mean()

        # Guardar la mejor precisión
        if accuracy > best_accuracy:
            best_accuracy = accuracy
            best_params = params

    results[idx] = (best_accuracy, best_params)

if __name__ == '__main__':
    # Número de hilos 
    N_THREADS = 6
    # Dividir las combinaciones de hiperparámetros en partes para cada hilo usando la nueva función
    splits = nivelacion_cargas_mejorada(combinations_rf, N_THREADS)
    
    # Crear un arreglo para almacenar los resultados de cada hilo
    results = [None] * N_THREADS
    threads = []

    # temporizador
    start_time = time.perf_counter()

    # Crear y comenzar los hilos 
    for i in range(N_THREADS):
        thread = threading.Thread(target=evaluate_set, args=(splits[i], X_train, y_train, results, i))
        threads.append(thread)
        thread.start()

    # Esperar a que todos los hilos terminen
    for thread in threads:
        thread.join()

    best_accuracy = max(results, key=lambda x: x[0])[0]
    best_params = max(results, key=lambda x: x[0])[1]

    finish_time = time.perf_counter()
    
    print(f"Mejor Precisión (cross-validation): {best_accuracy:.4f} con Hiperparámetros: {best_params}")
    print(f"Grid Search paralelizado completado en {finish_time - start_time:.2f} segundos")

    # Evaluar el modelo con los mejores hiperparámetros en el conjunto de prueba
    final_clf = RandomForestClassifier(**best_params)
    final_clf.fit(X_train, y_train)
    y_pred = final_clf.predict(X_test)
    test_accuracy = accuracy_score(y_test, y_pred)
    print(f"Precisión en el conjunto de prueba: {test_accuracy:.4f}")
